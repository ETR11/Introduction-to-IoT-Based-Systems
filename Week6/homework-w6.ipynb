{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BL40A2010 Introduction to IoT-Based Systems\n\n## Assignment 6, 30.10.2022\n\n### Author: Eero Suomalainen","metadata":{}},{"cell_type":"markdown","source":"**Prisoner's dilemma** is a standard example of a game analyzed in game theory that shows why two completely rational individuals might not cooperate, even if it appears that it is in their best interests to do so. It was originally framed by Merrill Flood and Melvin Dresher while working at RAND in 1950. Albert W. Tucker formalized the game with prison sentence rewards and named it \"prisoner's dilemma\", presenting it as follows:\n\n\"Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communicating with the other. The prosecutors lack sufficient evidence to convict the pair on the principal charge, but they have enough to convict both on a lesser charge. Simultaneously, the prosecutors offer each prisoner a bargain. Each prisoner is given the opportunity either to betray the other by testifying that the other committed the crime, or to cooperate with the other by remaining silent. The possible outcomes are:\n\n- If A and B each betray the other (not-cooperating to each other), each of them serves $z$ years in prison (payoff of $-z$)\n- If A betrays B (not-cooperating with B) but B remains silent (cooperating with A), A will serve $y$ years in prison (payoff $-y$) and B will serve $w$ years  (payoff of $-w$).\n- If B betrays A (not-cooperating with A) but A remains silent (cooperating with B), B will serve $y$ years in prison (payoff $-y$) and A will serve $w$ years  (payoff of $-w$).\n- If A and B both remain silent, both of them will serve $x$ years in prison (payoff of $-x$).\"\n\nThe payoff table is presented below. \n\n|                | $B$ cooperates  | $B$ not-cooperating   |\n|----------------|:---------------:|--------------:|\n| $A$ cooperates |  $A \\rightarrow -x$   | $A\\rightarrow -w$  |\n|                |  $B\\rightarrow -x$   | $B\\rightarrow -y$  |\n|                |                 |               |\n| $A$ not-cooperating   |  $A\\rightarrow -y$   | $A\\rightarrow -z$  |\n|                |  $B\\rightarrow -w$   | $B\\rightarrow -z$  |\n\n**However, this is only a *Prisoner's Dilemma GAME* for A GIVEN RELATION between the years in prison (payoffs) as to be studied next.**\n\nps. Text adapted from [Wikipedia](https://en.wikipedia.org/wiki/Prisoner's_dilemma).","metadata":{}},{"cell_type":"markdown","source":"**(1) Consider the Prisoner's dilemma description given above.**\n\n**(a) What is the relation between the payoffs values $x\\geq 0$, $y\\geq 0$, $w\\geq 0$ and $z \\geq 0$ so that the game can be classified as [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma)?**\n\n**(b) Verify the results (i.e., the proposed inequality) with numerical examples using [nashpy](https://nashpy.readthedocs.io/en/stable/index.html). Please provide one example when the inequality holds and one it does not (check my example for Dove and Hawyk game).**","metadata":{}},{"cell_type":"code","source":"(a) Both being silent is better than both betraying each other so -x > -z.\n    Betraying while other remains silent is the most beneficial scenario so -y > -w.\n    Nash equilibrium occurs when on betrays and other remains silent. From this perspective -y > -x and -z > -w.\n    This way -y > -x > -z > -w.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install nashpy==0.0.21","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting nashpy==0.0.21\n  Downloading nashpy-0.0.21.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting numpy>=1.12.1\n  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting scipy>=0.19.0\n  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nashpy\n  Building wheel for nashpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nashpy: filename=nashpy-0.0.21-py3-none-any.whl size=15260 sha256=2c75a263865766c3fb8dfb4a89671508a688b2976c4382f84a5b036848bb802e\n  Stored in directory: /home/jovyan/.cache/pip/wheels/02/08/62/cf4fa931e0a317d180936b266169a57f4bb4eb801465bbe8a1\nSuccessfully built nashpy\nInstalling collected packages: numpy, scipy, nashpy\nSuccessfully installed nashpy-0.0.21 numpy-1.21.6 scipy-1.7.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport nashpy as nash","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Test 1 (-y > -x > -z > -w) -> x=1, y=0, z=2 and w=3\nA = [[-1, -3], [0, -2]]\nB = [[-1, 0], [-3, -2]]\npd = nash.Game(A, B)\npd","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Bi matrix game with payoff matrices:\n\nRow player:\n[[-1 -3]\n [ 0 -2]]\n\nColumn player:\n[[-1  0]\n [-3 -2]]"},"metadata":{}}]},{"cell_type":"code","source":"eqs = pd.support_enumeration()\nlist(eqs)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[(array([0., 1.]), array([0., 1.]))]"},"metadata":{}}]},{"cell_type":"code","source":"The output reads as follows: Both A and B cooperate with probability of 0 and both will betray with probability of 1.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test 2 (-w > -z) -> x=1, y=0, z=3 and w=2\nA = [[-1, -2], [0, -3]]\nB = [[-1, 0], [-2, -3]]\npd = nash.Game(A, B)\npd","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Bi matrix game with payoff matrices:\n\nRow player:\n[[-1 -2]\n [ 0 -3]]\n\nColumn player:\n[[-1  0]\n [-2 -3]]"},"metadata":{}}]},{"cell_type":"code","source":"eqs = pd.support_enumeration()\nlist(eqs)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[(array([1., 0.]), array([0., 1.])),\n (array([0., 1.]), array([1., 0.])),\n (array([0.5, 0.5]), array([0.5, 0.5]))]"},"metadata":{}}]},{"cell_type":"code","source":"The output reads as follows: First line: A cooperates with probability of 1 and betrays with probability of 0\n                                         while B cooperates with probability of 0\n                                         and betrays with probability of 1.\n        \n                             Second line: A cooperates with probability of 0 and betrays with probability of 1\n                                          while B cooperates with probability of 1\n                                          and betrays with probability of 0.\n                    \n                             Third line: Both A and B cooperate with probability of 0.5\n                                         and both will betray with probability of 0.5.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(2) Justify why the game from the previous exercise is or is not a good (reasonable) model when $A$ and $B$ are:**\n\n**1. Two trained members from the army when they are in prison.**\n\n\n**2. Competitive companies in the market discussing standardization.**\n\n\n**3. Two different autonomous IoT-based home energy management algorithms that are focus on energy efficiency.**\n\n\n**4. Two different autonomous IoT-based home energy management algorithms that are focus on profit maximization.**\n\n**ps. You need to think about the assumption used in Game Theory and in the Prisoner's dilemma problem setting.**","metadata":{}},{"cell_type":"markdown","source":"1. Yes. It's advantageous to batray other as you can get shortest sentance or second longest. If you cooperate you get    second shortest sentance or longest sentance.\n\n2. No. The most beneficial for both is to cooperate since this way they can agree on one standard but if one of them      betrays the other there are now two (possibly conflicting) standards. Same is if both betray.\n\n3. No as both work towards same goal and one really cannot get more energy efficient on cost of another.\n\n4. Maybe yes. If both work with sahred resources then betraying another can net more profits for one. Both betraying each other can be costly but it might be less costly than cooperating while other betrays.","metadata":{}}]}